{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "x78fWhwv3Krs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ht4ALf59J1Zm",
        "outputId": "997419ee-e912-4bff-ccb3-13956d8bc3a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-18124a0ec175>:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  data = data.groupby('USER_ID_HASH', group_keys=False, as_index=False).apply(calculate_time_diff)\n",
            "<ipython-input-2-18124a0ec175>:31: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  data = data.groupby('USER_ID_HASH', group_keys=False, as_index=False).apply(calculate_time_diff)\n",
            "<ipython-input-2-18124a0ec175>:49: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  filtered_data = data.groupby('USER_ID_HASH', group_keys=False).apply(filter_first_transition).reset_index(drop=True)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 146ms/step - loss: 737.7543 - mae: 26.8435 - val_loss: 744.5156 - val_mae: 26.9646 - learning_rate: 1.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 725.2964 - mae: 26.5761 - val_loss: 741.3126 - val_mae: 26.9045 - learning_rate: 1.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 715.8321 - mae: 26.4197 - val_loss: 737.4341 - val_mae: 26.8313 - learning_rate: 1.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 692.1136 - mae: 25.9213 - val_loss: 732.4086 - val_mae: 26.7361 - learning_rate: 1.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 684.0806 - mae: 25.7639 - val_loss: 725.7617 - val_mae: 26.6094 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 643.8372 - mae: 25.0060 - val_loss: 716.7482 - val_mae: 26.4357 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 626.0988 - mae: 24.6484 - val_loss: 703.5256 - val_mae: 26.1787 - learning_rate: 1.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - loss: 609.7986 - mae: 24.2757 - val_loss: 684.5997 - val_mae: 25.8074 - learning_rate: 1.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 178ms/step - loss: 582.5528 - mae: 23.7013 - val_loss: 660.0750 - val_mae: 25.3182 - learning_rate: 1.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 198ms/step - loss: 567.7120 - mae: 23.4193 - val_loss: 631.5430 - val_mae: 24.7370 - learning_rate: 1.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 153ms/step - loss: 546.5169 - mae: 22.9334 - val_loss: 600.6301 - val_mae: 24.0920 - learning_rate: 1.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 533.3314 - mae: 22.5434 - val_loss: 569.3961 - val_mae: 23.4235 - learning_rate: 1.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 509.9359 - mae: 22.0543 - val_loss: 539.1838 - val_mae: 22.7597 - learning_rate: 1.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - loss: 492.2075 - mae: 21.6664 - val_loss: 510.0416 - val_mae: 22.1033 - learning_rate: 1.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - loss: 474.6693 - mae: 21.2314 - val_loss: 482.6714 - val_mae: 21.4693 - learning_rate: 1.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - loss: 456.3635 - mae: 20.7696 - val_loss: 457.6353 - val_mae: 20.8711 - learning_rate: 1.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 440.5216 - mae: 20.3653 - val_loss: 434.4869 - val_mae: 20.3014 - learning_rate: 1.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 139ms/step - loss: 416.9779 - mae: 19.7940 - val_loss: 412.8578 - val_mae: 19.7504 - learning_rate: 1.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - loss: 398.9733 - mae: 19.2872 - val_loss: 392.6297 - val_mae: 19.2198 - learning_rate: 1.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 377.7421 - mae: 18.7914 - val_loss: 373.3729 - val_mae: 18.6991 - learning_rate: 1.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 372.4117 - mae: 18.6265 - val_loss: 354.3262 - val_mae: 18.1679 - learning_rate: 1.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 354.0231 - mae: 17.9837 - val_loss: 335.6495 - val_mae: 17.6298 - learning_rate: 1.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 326.2463 - mae: 17.2409 - val_loss: 317.5487 - val_mae: 17.0903 - learning_rate: 1.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 314.9977 - mae: 16.8497 - val_loss: 299.8209 - val_mae: 16.5455 - learning_rate: 1.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 292.9610 - mae: 16.2446 - val_loss: 282.0693 - val_mae: 15.9854 - learning_rate: 1.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 282.1984 - mae: 15.8644 - val_loss: 264.0391 - val_mae: 15.3984 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 259.3934 - mae: 15.1194 - val_loss: 245.3300 - val_mae: 14.7785 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 250.2355 - mae: 14.7431 - val_loss: 225.8087 - val_mae: 14.1079 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 223.4434 - mae: 13.9152 - val_loss: 204.1641 - val_mae: 13.3187 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 206.0585 - mae: 13.1782 - val_loss: 166.5248 - val_mae: 12.0254 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 170.3534 - mae: 12.0126 - val_loss: 115.2404 - val_mae: 10.0599 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 116.4357 - mae: 10.0070 - val_loss: 90.9454 - val_mae: 8.8352 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 84.9647 - mae: 8.4274 - val_loss: 66.1717 - val_mae: 7.3950 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 62.8655 - mae: 6.9128 - val_loss: 44.1767 - val_mae: 5.8195 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 42.1322 - mae: 5.2570 - val_loss: 30.5825 - val_mae: 4.4611 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 36.0289 - mae: 4.3357 - val_loss: 23.6766 - val_mae: 3.4738 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - loss: 26.0112 - mae: 3.4854 - val_loss: 20.4073 - val_mae: 2.8027 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 23.8912 - mae: 3.1712 - val_loss: 18.8990 - val_mae: 2.3987 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 28.3436 - mae: 3.3680 - val_loss: 18.0213 - val_mae: 2.0845 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 23.4288 - mae: 2.9790 - val_loss: 17.5577 - val_mae: 1.8415 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 23.6447 - mae: 2.9965 - val_loss: 17.3311 - val_mae: 1.6690 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 21.9301 - mae: 2.9250 - val_loss: 17.2266 - val_mae: 1.5632 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 21.7315 - mae: 2.8654 - val_loss: 17.1784 - val_mae: 1.5207 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 22.0667 - mae: 2.9732 - val_loss: 17.1389 - val_mae: 1.4933 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 24.2964 - mae: 3.0696 - val_loss: 17.1138 - val_mae: 1.4830 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 21.3397 - mae: 2.8461 - val_loss: 17.0911 - val_mae: 1.4767 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 24.3400 - mae: 3.0505 - val_loss: 17.0709 - val_mae: 1.4849 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 22.2190 - mae: 2.8368 - val_loss: 17.0514 - val_mae: 1.5064 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 25.1029 - mae: 3.0975 - val_loss: 17.0303 - val_mae: 1.5224 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 20.6337 - mae: 2.8379 - val_loss: 17.0118 - val_mae: 1.5306 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 21.6151 - mae: 2.8893 - val_loss: 16.9856 - val_mae: 1.5336 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 22.5453 - mae: 2.9575 - val_loss: 16.9592 - val_mae: 1.5461 - learning_rate: 1.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 23.8916 - mae: 3.0051 - val_loss: 16.9379 - val_mae: 1.5560 - learning_rate: 1.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 24.3479 - mae: 3.1018 - val_loss: 16.9153 - val_mae: 1.5686 - learning_rate: 1.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 21.7805 - mae: 2.9321 - val_loss: 16.8994 - val_mae: 1.5808 - learning_rate: 1.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 22.1142 - mae: 2.9291 - val_loss: 16.8818 - val_mae: 1.5930 - learning_rate: 1.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 23.2350 - mae: 2.9894 - val_loss: 16.8732 - val_mae: 1.5964 - learning_rate: 1.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 23.2591 - mae: 3.0267 - val_loss: 16.8743 - val_mae: 1.5977 - learning_rate: 1.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 22.2854 - mae: 2.9532 - val_loss: 16.8452 - val_mae: 1.6212 - learning_rate: 1.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 22.8826 - mae: 2.9983 - val_loss: 16.8209 - val_mae: 1.6482 - learning_rate: 1.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 22.0609 - mae: 2.9493 - val_loss: 16.8160 - val_mae: 1.6525 - learning_rate: 1.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - loss: 20.9121 - mae: 2.8613 - val_loss: 16.8080 - val_mae: 1.6587 - learning_rate: 1.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - loss: 21.4389 - mae: 2.9045 - val_loss: 16.8029 - val_mae: 1.6645 - learning_rate: 1.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 20.9958 - mae: 2.8951 - val_loss: 16.8074 - val_mae: 1.6675 - learning_rate: 1.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 23.4834 - mae: 3.0711 - val_loss: 16.7935 - val_mae: 1.6727 - learning_rate: 1.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 23.4355 - mae: 3.1108 - val_loss: 16.7910 - val_mae: 1.6786 - learning_rate: 1.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 22.4437 - mae: 2.9281 - val_loss: 16.7818 - val_mae: 1.6873 - learning_rate: 1.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 21.8553 - mae: 2.9684 - val_loss: 16.7594 - val_mae: 1.7039 - learning_rate: 1.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 20.8906 - mae: 2.8626 - val_loss: 16.7439 - val_mae: 1.7154 - learning_rate: 1.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 23.0328 - mae: 3.0447 - val_loss: 16.7219 - val_mae: 1.7404 - learning_rate: 1.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 23.4195 - mae: 3.0223 - val_loss: 16.7234 - val_mae: 1.7286 - learning_rate: 1.0000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 23.1321 - mae: 3.0374 - val_loss: 16.7232 - val_mae: 1.7243 - learning_rate: 1.0000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 21.8534 - mae: 2.9528 - val_loss: 16.7053 - val_mae: 1.7394 - learning_rate: 1.0000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 23.5230 - mae: 3.0764 - val_loss: 16.7045 - val_mae: 1.7345 - learning_rate: 1.0000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 23.6959 - mae: 3.0082 - val_loss: 16.7127 - val_mae: 1.7312 - learning_rate: 1.0000e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 21.4369 - mae: 2.9506 - val_loss: 16.6953 - val_mae: 1.7458 - learning_rate: 1.0000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 21.1913 - mae: 2.9456 - val_loss: 16.6767 - val_mae: 1.7702 - learning_rate: 1.0000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 22.2868 - mae: 3.0050 - val_loss: 16.6688 - val_mae: 1.7842 - learning_rate: 1.0000e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 21.1729 - mae: 2.9148 - val_loss: 16.6690 - val_mae: 1.7717 - learning_rate: 1.0000e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 22.5458 - mae: 3.0127 - val_loss: 16.6574 - val_mae: 1.7849 - learning_rate: 1.0000e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 22.3528 - mae: 3.0008 - val_loss: 16.6627 - val_mae: 1.7663 - learning_rate: 1.0000e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 22.5350 - mae: 3.0619 - val_loss: 16.6518 - val_mae: 1.7803 - learning_rate: 1.0000e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 23.7881 - mae: 3.0312 - val_loss: 16.6423 - val_mae: 1.7944 - learning_rate: 1.0000e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 21.1210 - mae: 2.8779 - val_loss: 16.6389 - val_mae: 1.8001 - learning_rate: 1.0000e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 21.9755 - mae: 2.9738 - val_loss: 16.6347 - val_mae: 1.8117 - learning_rate: 1.0000e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 20.5599 - mae: 2.8706 - val_loss: 16.6299 - val_mae: 1.8240 - learning_rate: 1.0000e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 21.1585 - mae: 2.9590 - val_loss: 16.6412 - val_mae: 1.8056 - learning_rate: 1.0000e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 20.2877 - mae: 2.8606 - val_loss: 16.6242 - val_mae: 1.8239 - learning_rate: 1.0000e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 130ms/step - loss: 21.6666 - mae: 3.0126 - val_loss: 16.6272 - val_mae: 1.8208 - learning_rate: 1.0000e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - loss: 21.7573 - mae: 2.9999 - val_loss: 16.6125 - val_mae: 1.8316 - learning_rate: 1.0000e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 21.1609 - mae: 2.9147 - val_loss: 16.5996 - val_mae: 1.8621 - learning_rate: 1.0000e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 20.9365 - mae: 2.9220 - val_loss: 16.5942 - val_mae: 1.8733 - learning_rate: 1.0000e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 21.9843 - mae: 2.9987 - val_loss: 16.5906 - val_mae: 1.8729 - learning_rate: 1.0000e-04\n",
            "Epoch 94/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 23.8676 - mae: 3.1373 - val_loss: 16.5897 - val_mae: 1.8583 - learning_rate: 1.0000e-04\n",
            "Epoch 95/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 22.7244 - mae: 3.0120 - val_loss: 16.5865 - val_mae: 1.8560 - learning_rate: 1.0000e-04\n",
            "Epoch 96/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 20.8872 - mae: 2.9112 - val_loss: 16.5774 - val_mae: 1.8677 - learning_rate: 1.0000e-04\n",
            "Epoch 97/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 20.4516 - mae: 2.8776 - val_loss: 16.5820 - val_mae: 1.8621 - learning_rate: 1.0000e-04\n",
            "Epoch 98/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 21.3116 - mae: 2.9558 - val_loss: 16.5799 - val_mae: 1.8529 - learning_rate: 1.0000e-04\n",
            "Epoch 99/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 23.3240 - mae: 3.1122 - val_loss: 16.5655 - val_mae: 1.8897 - learning_rate: 1.0000e-04\n",
            "Epoch 100/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 21.8308 - mae: 2.9799 - val_loss: 16.5657 - val_mae: 1.8811 - learning_rate: 1.0000e-04\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
            "=== 模型評估結果 ===\n",
            "Mean Absolute Error (MAE): 1.8897\n",
            "Mean Squared Error (MSE): 16.5655\n",
            "Root Mean Squared Error (RMSE): 4.0701\n",
            "R² Score: 0.0465\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.impute import KNNImputer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, GRU\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# === Step 1: 讀取資料 ===\n",
        "data = pd.read_csv('/content/all_plot_cleandata.csv', encoding='utf-8')\n",
        "\n",
        "# === Step 2: 新增轉變標籤 ===\n",
        "data['Transition'] = data.groupby('USER_ID_HASH')['Exhausted_state'].transform(\n",
        "    lambda x: (x.shift() == 0) & (x == 1)\n",
        ").astype(int)\n",
        "\n",
        "# === Step 3: 計算首次轉變時間差 ===\n",
        "def calculate_time_diff(df):\n",
        "    start_time = df['time'].iloc[0]\n",
        "    if df['Transition'].sum() > 0:  # 如果有轉變\n",
        "        transition_time = df.loc[df['Transition'] == 1, 'time'].iloc[0]\n",
        "        df['time_diff_to_first_exhausted'] = transition_time - start_time\n",
        "    else:\n",
        "        df['time_diff_to_first_exhausted'] = None\n",
        "    return df\n",
        "\n",
        "data = data.groupby('USER_ID_HASH', group_keys=False, as_index=False).apply(calculate_time_diff)\n",
        "\n",
        "# === Step 4: 計算移動特徵 ===\n",
        "def add_moving_features(df):\n",
        "    df['distance_moving_avg'] = df.groupby('USER_ID_HASH')['distance'].transform(\n",
        "        lambda x: x.rolling(window=5, min_periods=1).mean()\n",
        "    )\n",
        "    return df\n",
        "\n",
        "data = add_moving_features(data)\n",
        "\n",
        "# === Step 5: 過濾資料 ===\n",
        "def filter_first_transition(df):\n",
        "    if df['Transition'].sum() == 0:\n",
        "        return df\n",
        "    first_transition_index = df[df['Transition'] == 1].index[0]\n",
        "    return df[df.index <= first_transition_index]\n",
        "\n",
        "filtered_data = data.groupby('USER_ID_HASH', group_keys=False).apply(filter_first_transition).reset_index(drop=True)\n",
        "\n",
        "# 填補缺失值\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "filtered_data['time_diff_to_first_exhausted'] = imputer.fit_transform(filtered_data[['time_diff_to_first_exhausted']])\n",
        "\n",
        "# 特徵選擇\n",
        "y = filtered_data['time_diff_to_first_exhausted']\n",
        "X = filtered_data[['distance', 'distance_moving_avg']]  # 這裡選了主要特徵，你可以根據需求調整\n",
        "\n",
        "# === Step 6: 標準化數據 & 時間步長設置 ===\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# 時序化數據\n",
        "time_steps = 10  # 設定時間步長\n",
        "def create_time_series(X, y, time_steps):\n",
        "    X_time_series, y_time_series = [], []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        X_time_series.append(X[i:i + time_steps])\n",
        "        y_time_series.append(y[i + time_steps])\n",
        "    return np.array(X_time_series), np.array(y_time_series)\n",
        "\n",
        "X_time_series, y_time_series = create_time_series(X_scaled, y.values, time_steps)\n",
        "\n",
        "# 切分資料集\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_time_series, y_time_series, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# 回調函數\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "\n",
        "# 優化後的 LSTM 模型\n",
        "model = Sequential([\n",
        "    LSTM(128, activation='tanh', return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    Dropout(0.3),  # 增加 Dropout\n",
        "    BatchNormalization(),  # 加入批次正規化\n",
        "    LSTM(64, activation='tanh', return_sequences=False),\n",
        "    Dropout(0.3),\n",
        "    Dense(32),\n",
        "    LeakyReLU(alpha=0.1),  # 使用 LeakyReLU 代替 ReLU\n",
        "    Dense(16),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    Dense(1)  # 輸出層\n",
        "])\n",
        "\n",
        "# 編譯模型\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='mse', metrics=['mae'])\n",
        "\n",
        "# 訓練模型\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=100,\n",
        "    batch_size=128,  # 增大批量大小，可能加速收斂\n",
        "    callbacks=[early_stopping, reduce_lr],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 評估模型\n",
        "y_pred = model.predict(X_test)\n",
        "mae = np.mean(np.abs(y_test - y_pred.flatten()))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"=== 模型評估結果 ===\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "print(f\"Mean Squared Error (MSE): {mean_squared_error(y_test, y_pred):.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
        "print(f\"R² Score: {r2:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNN\n"
      ],
      "metadata": {
        "id": "I_M1g66V3IQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, BatchNormalization, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# === Step 1: 讀取資料 ===\n",
        "data = pd.read_csv('/content/all_plot_cleandata.csv', encoding='utf-8')\n",
        "\n",
        "# === Step 2: 新增轉變標籤 ===\n",
        "data['Transition'] = data.groupby('USER_ID_HASH')['Exhausted_state'].transform(\n",
        "    lambda x: (x.shift() == 0) & (x == 1)\n",
        ").astype(int)\n",
        "\n",
        "# === Step 3: 計算首次轉變時間差 ===\n",
        "def calculate_time_diff(df):\n",
        "    start_time = df['time'].iloc[0]\n",
        "    if df['Transition'].sum() > 0:  # 如果有轉變\n",
        "        transition_time = df.loc[df['Transition'] == 1, 'time'].iloc[0]\n",
        "        df['time_diff_to_first_exhausted'] = transition_time - start_time\n",
        "    else:\n",
        "        df['time_diff_to_first_exhausted'] = None\n",
        "    return df\n",
        "\n",
        "data = data.groupby('USER_ID_HASH', group_keys=False, as_index=False).apply(calculate_time_diff)\n",
        "\n",
        "# === Step 4: 計算移動特徵 ===\n",
        "def add_moving_features(df):\n",
        "    df['distance_moving_avg'] = df.groupby('USER_ID_HASH')['distance'].transform(\n",
        "        lambda x: x.rolling(window=5, min_periods=1).mean()\n",
        "    )\n",
        "    df['cumulative_distance'] = df.groupby('USER_ID_HASH')['distance'].cumsum()\n",
        "    df['cumulative_time'] = df.groupby('USER_ID_HASH')['time'].transform(lambda x: x - x.min())\n",
        "    return df\n",
        "\n",
        "data = add_moving_features(data)\n",
        "\n",
        "# === Step 5: 過濾資料 ===\n",
        "def filter_first_transition(df):\n",
        "    if df['Transition'].sum() == 0:\n",
        "        return df\n",
        "    first_transition_index = df[df['Transition'] == 1].index[0]\n",
        "    return df[df.index <= first_transition_index]\n",
        "\n",
        "filtered_data = data.groupby('USER_ID_HASH', group_keys=False).apply(filter_first_transition).reset_index(drop=True)\n",
        "\n",
        "# 填補缺失值\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "filtered_data['time_diff_to_first_exhausted'] = imputer.fit_transform(filtered_data[['time_diff_to_first_exhausted']])\n",
        "\n",
        "# 特徵選擇\n",
        "y = filtered_data['time_diff_to_first_exhausted']\n",
        "X = filtered_data[['distance', 'distance_moving_avg']]\n",
        "\n",
        "# === Step 6: 標準化數據 & 時間步長設置 ===\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# 時序化數據\n",
        "time_steps = 10  # 設定時間步長\n",
        "def create_time_series(X, y, time_steps):\n",
        "    X_time_series, y_time_series = [], []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        X_time_series.append(X[i:i + time_steps])\n",
        "        y_time_series.append(y[i + time_steps])\n",
        "    return np.array(X_time_series), np.array(y_time_series)\n",
        "\n",
        "X_time_series, y_time_series = create_time_series(X_scaled, y.values, time_steps)\n",
        "\n",
        "# 切分資料集\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_time_series, y_time_series, test_size=0.2, random_state=42)\n",
        "\n",
        "# === Step 7: 建立 RNN 模型 ===\n",
        "model = Sequential([\n",
        "    LSTM(128, activation='tanh', return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    Dropout(0.3),  # 增加 Dropout\n",
        "    BatchNormalization(),  # 加入批次正規化\n",
        "    LSTM(64, activation='tanh', return_sequences=False),\n",
        "    Dropout(0.3),\n",
        "    Dense(32),\n",
        "    LeakyReLU(alpha=0.1),  # 使用 LeakyReLU 代替 ReLU\n",
        "    Dense(16),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    Dense(1)  # 輸出層\n",
        "])\n",
        "\n",
        "# 編譯模型\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='mse', metrics=['mae'])\n",
        "\n",
        "# 回調函數\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "\n",
        "# === Step 8: 訓練模型 ===\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=100,\n",
        "    batch_size=128,\n",
        "    callbacks=[early_stopping, reduce_lr],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# === Step 9: 評估模型 ===\n",
        "y_pred = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred.flatten())\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"=== 模型評估結果 ===\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "print(f\"R² Score: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "388JdJUs3Byt",
        "outputId": "1adb1c8e-9f6a-4149-eb4a-4939da6655b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-90bd1f0804a3>:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  data = data.groupby('USER_ID_HASH', group_keys=False, as_index=False).apply(calculate_time_diff)\n",
            "<ipython-input-3-90bd1f0804a3>:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  data = data.groupby('USER_ID_HASH', group_keys=False, as_index=False).apply(calculate_time_diff)\n",
            "<ipython-input-3-90bd1f0804a3>:48: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  filtered_data = data.groupby('USER_ID_HASH', group_keys=False).apply(filter_first_transition).reset_index(drop=True)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - loss: 731.2254 - mae: 26.7430 - val_loss: 743.7923 - val_mae: 26.9520 - learning_rate: 1.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 719.5164 - mae: 26.4520 - val_loss: 739.2968 - val_mae: 26.8694 - learning_rate: 1.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 698.5239 - mae: 26.0827 - val_loss: 733.3384 - val_mae: 26.7590 - learning_rate: 1.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - loss: 675.8227 - mae: 25.6611 - val_loss: 725.5425 - val_mae: 26.6127 - learning_rate: 1.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 649.1505 - mae: 25.1233 - val_loss: 714.8561 - val_mae: 26.4105 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 614.7086 - mae: 24.4301 - val_loss: 700.1863 - val_mae: 26.1298 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 584.2412 - mae: 23.7595 - val_loss: 680.2480 - val_mae: 25.7423 - learning_rate: 1.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 567.4677 - mae: 23.3957 - val_loss: 654.8793 - val_mae: 25.2391 - learning_rate: 1.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 538.5192 - mae: 22.7409 - val_loss: 623.9460 - val_mae: 24.6099 - learning_rate: 1.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 517.2855 - mae: 22.3047 - val_loss: 588.7029 - val_mae: 23.8720 - learning_rate: 1.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 485.8758 - mae: 21.5985 - val_loss: 551.2744 - val_mae: 23.0629 - learning_rate: 1.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 461.6335 - mae: 20.9871 - val_loss: 513.2041 - val_mae: 22.2125 - learning_rate: 1.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 442.6882 - mae: 20.5076 - val_loss: 474.0847 - val_mae: 21.3037 - learning_rate: 1.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 415.2035 - mae: 19.8487 - val_loss: 435.0204 - val_mae: 20.3568 - learning_rate: 1.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 389.2639 - mae: 19.1423 - val_loss: 397.6406 - val_mae: 19.4085 - learning_rate: 1.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - loss: 366.7145 - mae: 18.4976 - val_loss: 363.3690 - val_mae: 18.4982 - learning_rate: 1.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 341.3770 - mae: 17.8429 - val_loss: 332.3510 - val_mae: 17.6317 - learning_rate: 1.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 311.8871 - mae: 16.9227 - val_loss: 304.3694 - val_mae: 16.8092 - learning_rate: 1.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 295.8651 - mae: 16.4880 - val_loss: 279.0288 - val_mae: 16.0267 - learning_rate: 1.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 279.6568 - mae: 15.8874 - val_loss: 255.5088 - val_mae: 15.2648 - learning_rate: 1.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 250.1749 - mae: 14.9870 - val_loss: 233.5157 - val_mae: 14.5272 - learning_rate: 1.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 234.2713 - mae: 14.4564 - val_loss: 212.2935 - val_mae: 13.7689 - learning_rate: 1.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 216.7668 - mae: 13.7362 - val_loss: 192.5101 - val_mae: 13.0149 - learning_rate: 1.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 193.2537 - mae: 12.9238 - val_loss: 174.2757 - val_mae: 12.2724 - learning_rate: 1.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 178.7181 - mae: 12.2705 - val_loss: 157.3344 - val_mae: 11.5331 - learning_rate: 1.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 155.2188 - mae: 11.4680 - val_loss: 142.0492 - val_mae: 10.8159 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 143.8259 - mae: 10.7252 - val_loss: 128.5634 - val_mae: 10.1466 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 129.4339 - mae: 10.0392 - val_loss: 115.8868 - val_mae: 9.5016 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 116.4362 - mae: 9.3483 - val_loss: 104.1850 - val_mae: 8.8534 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 109.8006 - mae: 8.8011 - val_loss: 93.1459 - val_mae: 8.1799 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 92.0196 - mae: 7.9296 - val_loss: 82.9062 - val_mae: 7.4846 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 90.8376 - mae: 7.4817 - val_loss: 74.3976 - val_mae: 6.8122 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 78.8641 - mae: 6.7928 - val_loss: 67.0808 - val_mae: 6.2136 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 75.8780 - mae: 6.2587 - val_loss: 59.7724 - val_mae: 5.5898 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 64.9276 - mae: 5.6074 - val_loss: 54.4149 - val_mae: 5.0573 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 61.5144 - mae: 5.3436 - val_loss: 49.6048 - val_mae: 4.5681 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 57.6140 - mae: 5.1751 - val_loss: 44.3795 - val_mae: 4.0119 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - loss: 50.2559 - mae: 4.7294 - val_loss: 35.8135 - val_mae: 3.3046 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - loss: 48.0576 - mae: 4.6497 - val_loss: 18.3855 - val_mae: 2.0589 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - loss: 30.6595 - mae: 3.8934 - val_loss: 18.2489 - val_mae: 1.9590 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 22.4350 - mae: 3.1918 - val_loss: 17.9887 - val_mae: 2.0485 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 24.4456 - mae: 3.3427 - val_loss: 17.7506 - val_mae: 1.9941 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 23.8090 - mae: 3.3052 - val_loss: 17.3379 - val_mae: 1.8426 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 25.0261 - mae: 3.3134 - val_loss: 17.2094 - val_mae: 1.7613 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 23.0409 - mae: 3.2390 - val_loss: 17.1757 - val_mae: 1.7419 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 22.8806 - mae: 3.2067 - val_loss: 17.2012 - val_mae: 1.7700 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 24.2803 - mae: 3.2920 - val_loss: 17.2002 - val_mae: 1.7862 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - loss: 22.7520 - mae: 3.1942 - val_loss: 17.1909 - val_mae: 1.8047 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - loss: 24.6049 - mae: 3.3452 - val_loss: 17.1219 - val_mae: 1.8288 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - loss: 22.8565 - mae: 3.2183 - val_loss: 17.1501 - val_mae: 1.8727 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 23.8889 - mae: 3.2321 - val_loss: 17.2024 - val_mae: 1.9072 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 22.1642 - mae: 3.1062 - val_loss: 17.1164 - val_mae: 1.9053 - learning_rate: 1.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 22.2841 - mae: 3.1923 - val_loss: 17.1382 - val_mae: 1.9157 - learning_rate: 1.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 21.5857 - mae: 3.0834 - val_loss: 17.1658 - val_mae: 1.9417 - learning_rate: 1.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 21.6602 - mae: 3.0952 - val_loss: 17.1739 - val_mae: 1.9806 - learning_rate: 1.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 22.9083 - mae: 3.2675 - val_loss: 17.1771 - val_mae: 2.0266 - learning_rate: 1.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 22.2750 - mae: 3.1707 - val_loss: 17.1497 - val_mae: 2.0378 - learning_rate: 1.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 23.6422 - mae: 3.2104 - val_loss: 17.1605 - val_mae: 2.0527 - learning_rate: 5.0000e-05\n",
            "Epoch 59/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 23.9385 - mae: 3.3085 - val_loss: 17.1601 - val_mae: 2.0660 - learning_rate: 5.0000e-05\n",
            "Epoch 60/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - loss: 24.0125 - mae: 3.3201 - val_loss: 17.2318 - val_mae: 2.0762 - learning_rate: 5.0000e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - loss: 23.9813 - mae: 3.2231 - val_loss: 17.2185 - val_mae: 2.0706 - learning_rate: 5.0000e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - loss: 23.8246 - mae: 3.2475 - val_loss: 17.2246 - val_mae: 2.0784 - learning_rate: 5.0000e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 23.3157 - mae: 3.2238 - val_loss: 17.2425 - val_mae: 2.0871 - learning_rate: 2.5000e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 22.6224 - mae: 3.2069 - val_loss: 17.2443 - val_mae: 2.0951 - learning_rate: 2.5000e-05\n",
            "Epoch 65/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 20.6848 - mae: 3.0963 - val_loss: 17.2372 - val_mae: 2.1000 - learning_rate: 2.5000e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 24.2224 - mae: 3.2846 - val_loss: 17.2289 - val_mae: 2.1073 - learning_rate: 2.5000e-05\n",
            "Epoch 67/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 22.4075 - mae: 3.2272 - val_loss: 17.2307 - val_mae: 2.1102 - learning_rate: 2.5000e-05\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n",
            "=== 模型評估結果 ===\n",
            "Mean Absolute Error (MAE): 1.9053\n",
            "Mean Squared Error (MSE): 17.1164\n",
            "Root Mean Squared Error (RMSE): 4.1372\n",
            "R² Score: 0.0148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_data.columns.tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwBBz7a5jy0Q",
        "outputId": "4eb1f5d1-b0e9-4687-bbb0-f3ae3924fea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['USER_ID_HASH',\n",
              " 'age',\n",
              " 'gender',\n",
              " 'right_eye_condition',\n",
              " 'right_eye_degree',\n",
              " 'right_eye_shine',\n",
              " 'right_eye_shine_degree',\n",
              " 'left_eye_condition',\n",
              " 'left_eye_degree',\n",
              " 'left_eye_shine',\n",
              " 'left_eye_shine_degree',\n",
              " 'eye_situation_value1',\n",
              " 'eye_situation_value2',\n",
              " 'eye_situation_value3',\n",
              " 'eye_situation_value4',\n",
              " 'eye_situation_value5',\n",
              " 'use_situation1',\n",
              " 'use_situation3',\n",
              " 'habit1',\n",
              " 'distance',\n",
              " 'brightness_x',\n",
              " 'blink_x',\n",
              " 'state',\n",
              " 'Exhausted_state',\n",
              " 'time',\n",
              " 'distance_ratio',\n",
              " 'brightness_y',\n",
              " 'blink_y',\n",
              " 'blink_num',\n",
              " 'question_5',\n",
              " 'question_6',\n",
              " 'question_7',\n",
              " 'question_8',\n",
              " 'question_9',\n",
              " 'question_10',\n",
              " 'question_11',\n",
              " 'use_situation2_3小時以內',\n",
              " 'use_situation2_3至6小時',\n",
              " 'use_situation2_6-9小時',\n",
              " 'use_situation2_9-12小時',\n",
              " 'use_situation2_12小時以上',\n",
              " 'use_situation_value4_電腦自動調整',\n",
              " 'use_situation_value4_不常調整',\n",
              " 'use_situation_value4_每次使用都會調整',\n",
              " 'use_situation_value5_僅室內共用燈光',\n",
              " 'use_situation_value5_僅室內專用燈光',\n",
              " 'use_situation_value5_室內共用與專用燈光皆有',\n",
              " 'use_situation_value5_戶外',\n",
              " 'use_situation_value5_光線明顯不足之環境',\n",
              " 'use_situation_value5_其他',\n",
              " 'habit2_無',\n",
              " 'habit2_半年一次',\n",
              " 'habit2_一年一次',\n",
              " 'habit2_更頻繁',\n",
              " 'habit3_低於4小時',\n",
              " 'habit3_4至6小時',\n",
              " 'habit3_6至8小時',\n",
              " 'habit3_高於8小時',\n",
              " 'habit4_0或1次',\n",
              " 'habit4_2或3次',\n",
              " 'habit4_4或5次',\n",
              " 'habit4_6次以上',\n",
              " 'habit5_無休息',\n",
              " 'habit5_1小時內',\n",
              " 'habit5_1-2小時',\n",
              " 'habit5_2-3小時',\n",
              " 'habit5_3-4小時',\n",
              " 'habit5_4-5小時',\n",
              " 'habit5_5小時以上',\n",
              " 'habit6_10分鐘內',\n",
              " 'habit6_11-30分鐘',\n",
              " 'habit6_31-60分鐘',\n",
              " 'habit6_60分鐘以上',\n",
              " 'habit7_眼部運動',\n",
              " 'habit7_閉目養神',\n",
              " 'habit7_其他',\n",
              " 'habit7_閉目養神, 眼部運動',\n",
              " 'habit7_閉目養神, 其他',\n",
              " 'habit7_眼部運動, 其他',\n",
              " 'habit7_閉目養神, 眼部運動, 其他',\n",
              " 'question_1_電腦',\n",
              " 'question_1_手機',\n",
              " 'question_1_平板',\n",
              " 'question_1_其他',\n",
              " 'question_2_工作/實習用途',\n",
              " 'question_2_聆聽線上課程',\n",
              " 'question_2_完成學校作業',\n",
              " 'question_2_打電腦遊戲',\n",
              " 'question_2_觀看影音串流平台(如youtube)',\n",
              " 'question_2_回復訊息文字',\n",
              " 'question_2_其他',\n",
              " 'question_3_僅室內共用燈光',\n",
              " 'question_3_僅室內專用燈光',\n",
              " 'question_3_戶外',\n",
              " 'question_3_光線明顯不足之環境',\n",
              " 'question_3_其他',\n",
              " 'question_4_無',\n",
              " 'question_4_配戴眼鏡',\n",
              " 'question_4_配戴隱形眼鏡',\n",
              " 'Transition',\n",
              " 'time_diff_to_first_exhausted',\n",
              " 'distance_moving_avg',\n",
              " 'brightness_moving_avg',\n",
              " 'distance_variance']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "# 儲存模型\n",
        "joblib.dump(model, 'modelrnn.joblib')  # 將模型保存到文件中\n",
        "joblib.dump(scaler, 'scalerrnn.joblib')        # 保存標準化對象\n",
        "\n",
        "print(\"模型已成功保存！\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHG2nQaFhqju",
        "outputId": "812d92bb-26b9-4c37-8889-9609814a9228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "模型已成功保存！\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##預測"
      ],
      "metadata": {
        "id": "NhI6_tlfjNcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# 載入保存的模型和標準化器\n",
        "model = joblib.load('modelrnn.joblib')\n",
        "scaler = joblib.load('scalerrnn.joblib')"
      ],
      "metadata": {
        "id": "AgToqCldjRzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "new_data = pd.read_csv('/content/Joy_final_data.csv', encoding='utf-8')\n",
        "\n",
        "# 處理新資料集的特徵選擇（根據訓練時選擇的特徵進行處理）\n",
        "new_data_selected = new_data[['age',\n",
        " 'gender',\n",
        " 'right_eye_condition',\n",
        " 'right_eye_degree',\n",
        " 'right_eye_shine',\n",
        " 'right_eye_shine_degree',\n",
        " 'left_eye_condition',\n",
        " 'left_eye_degree',\n",
        " 'left_eye_shine',\n",
        " 'left_eye_shine_degree',\n",
        " 'eye_situation_value1',\n",
        " 'eye_situation_value3',\n",
        " 'eye_situation_value4',\n",
        " 'eye_situation_value5',\n",
        " 'use_situation1',\n",
        " 'use_situation3',\n",
        " 'habit1',\n",
        " 'distance',\n",
        " 'brightness_x',\n",
        " 'blink_x',\n",
        " 'state',\n",
        " 'Exhausted_state',\n",
        " 'time',\n",
        " 'distance_ratio',\n",
        " 'brightness_y',\n",
        " 'blink_y',\n",
        " 'blink_num',\n",
        " 'question_5',\n",
        " 'question_6',\n",
        " 'question_7',\n",
        " 'question_8',\n",
        " 'question_9',\n",
        " 'question_10',\n",
        " 'question_11',\n",
        " 'use_situation2_3小時以內',\n",
        " 'use_situation2_3至6小時',\n",
        " 'use_situation2_6-9小時',\n",
        " 'use_situation2_9-12小時',\n",
        " 'use_situation2_12小時以上',\n",
        " 'use_situation_value4_電腦自動調整',\n",
        " 'use_situation_value4_不常調整',\n",
        " 'use_situation_value4_每次使用都會調整',\n",
        " 'use_situation_value5_僅室內共用燈光',\n",
        " 'use_situation_value5_僅室內專用燈光',\n",
        " 'use_situation_value5_室內共用與專用燈光皆有',\n",
        " 'use_situation_value5_戶外',\n",
        " 'use_situation_value5_光線明顯不足之環境',\n",
        " 'use_situation_value5_其他',\n",
        " 'habit2_無',\n",
        " 'habit2_半年一次',\n",
        " 'habit2_一年一次',\n",
        " 'habit2_更頻繁',\n",
        " 'habit3_低於4小時',\n",
        " 'habit3_4至6小時',\n",
        " 'habit3_6至8小時',\n",
        " 'habit3_高於8小時',\n",
        " 'habit4_0或1次',\n",
        " 'habit4_2或3次',\n",
        " 'habit4_4或5次',\n",
        " 'habit4_6次以上',\n",
        " 'habit5_無休息',\n",
        " 'habit6_10分鐘內',\n",
        " 'habit7_閉目養神',\n",
        " 'habit7_閉目養神, 眼部運動, 其他',\n",
        " 'question_1_電腦',\n",
        " 'question_1_平板',\n",
        " 'question_1_其他',\n",
        " 'question_2_工作/實習用途',\n",
        " 'question_2_聆聽線上課程',\n",
        " 'question_2_完成學校作業',\n",
        " 'question_2_其他',\n",
        " 'question_3_僅室內共用燈光',\n",
        " 'question_3_其他',\n",
        " 'question_4_無',\n",
        " 'question_4_配戴眼鏡',\n",
        " 'question_4_配戴隱形眼鏡',\n",
        " 'brightness_moving_avg',\n",
        " 'distance_variance']]  # 根據你的特徵選擇\n",
        "\n",
        "print(len(new_data_selected.columns))\n",
        "\n",
        "# 對新資料進行標準化\n",
        "new_data_scaled = scaler.transform(new_data_selected)\n",
        "\n",
        "# 時序化資料\n",
        "def create_time_series(X, time_steps):\n",
        "    X_time_series = []\n",
        "    for i in range(len(X) - time_steps):\n",
        "        X_time_series.append(X[i:i + time_steps])\n",
        "    return np.array(X_time_series)\n",
        "\n",
        "time_steps = 10  # 時間步長設定為與訓練時相同\n",
        "new_data_time_series = create_time_series(new_data_scaled, time_steps)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJd5KuSMjUV_",
        "outputId": "21420512-8a1f-446d-d67d-274a90ca1286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用已載入的模型進行預測\n",
        "predictions = model.predict(new_data_time_series)\n",
        "\n",
        "# 預測結果\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-7SyaOokcQV",
        "outputId": "d77b0492-0395-46f0-fd78-aa8fdf672403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step\n",
            "[[3.35535  ]\n",
            " [3.3680477]\n",
            " [3.3701365]\n",
            " [3.364417 ]\n",
            " [3.3616483]\n",
            " [3.3565297]\n",
            " [3.3515337]\n",
            " [3.3531446]\n",
            " [3.3500657]\n",
            " [3.3464947]\n",
            " [3.3471117]\n",
            " [3.3393412]\n",
            " [3.3344166]\n",
            " [3.3405294]\n",
            " [3.3428555]\n",
            " [3.3476076]\n",
            " [3.3620498]\n",
            " [3.3586001]\n",
            " [3.3529618]\n",
            " [3.346035 ]\n",
            " [3.3436313]\n",
            " [3.341132 ]\n",
            " [3.3390493]\n",
            " [3.3356838]\n",
            " [3.3310742]\n",
            " [3.3409145]\n",
            " [3.3460069]\n",
            " [3.3410215]\n",
            " [3.33735  ]\n",
            " [3.3373573]\n",
            " [3.3335857]\n",
            " [3.3320065]\n",
            " [3.3293822]\n",
            " [3.3283105]\n",
            " [3.3308744]\n",
            " [3.3292532]\n",
            " [3.324361 ]\n",
            " [3.3251314]\n",
            " [3.3247054]\n",
            " [3.327608 ]\n",
            " [3.3317504]\n",
            " [3.332581 ]\n",
            " [3.3361502]\n",
            " [3.3418922]\n",
            " [3.3444777]\n",
            " [3.3432543]\n",
            " [3.3444138]\n",
            " [3.355331 ]\n",
            " [3.3528364]\n",
            " [3.3533704]\n",
            " [3.3631754]\n",
            " [3.3796318]\n",
            " [3.3882756]\n",
            " [3.39531  ]\n",
            " [3.3975143]\n",
            " [3.402921 ]\n",
            " [3.4122581]\n",
            " [3.4121957]\n",
            " [3.4170299]\n",
            " [3.4073596]\n",
            " [3.4327335]\n",
            " [3.433877 ]\n",
            " [3.4270601]\n",
            " [3.4214573]\n",
            " [3.4138985]\n",
            " [3.40584  ]\n",
            " [3.39893  ]\n",
            " [3.3904958]\n",
            " [3.3858602]\n",
            " [3.3809338]\n",
            " [3.381147 ]\n",
            " [3.3830566]\n",
            " [3.3840938]\n",
            " [3.38197  ]\n",
            " [3.380291 ]\n",
            " [3.3799682]\n",
            " [3.3790581]\n",
            " [3.380364 ]\n",
            " [3.383002 ]\n",
            " [3.382978 ]\n",
            " [3.3807719]\n",
            " [3.3775272]\n",
            " [3.3754   ]\n",
            " [3.3703494]\n",
            " [3.368836 ]\n",
            " [3.3653674]\n",
            " [3.3632216]\n",
            " [3.3657947]\n",
            " [3.3628101]\n",
            " [3.3597627]\n",
            " [3.360694 ]\n",
            " [3.3604739]\n",
            " [3.354126 ]\n",
            " [3.3405714]\n",
            " [3.3460894]\n",
            " [3.3244896]\n",
            " [3.2886572]\n",
            " [3.2613864]\n",
            " [3.2339263]\n",
            " [3.2072713]\n",
            " [3.1876674]\n",
            " [3.1731355]\n",
            " [3.1476574]\n",
            " [3.1111262]\n",
            " [3.1085424]\n",
            " [3.1168914]\n",
            " [3.11411  ]\n",
            " [3.1048937]\n",
            " [3.1078548]\n",
            " [3.112589 ]\n",
            " [3.1116738]\n",
            " [3.1040611]\n",
            " [3.1006594]\n",
            " [3.2015195]\n",
            " [3.2805767]\n",
            " [3.334331 ]\n",
            " [3.3817782]\n",
            " [3.4220505]\n",
            " [3.4427595]\n",
            " [3.4675756]\n",
            " [3.4829032]\n",
            " [3.4966264]\n",
            " [3.507184 ]\n",
            " [3.510068 ]\n",
            " [3.5126624]\n",
            " [3.5096312]\n",
            " [3.5021725]\n",
            " [3.4982097]\n",
            " [3.4936285]\n",
            " [3.4838057]\n",
            " [3.4780006]\n",
            " [3.4803133]\n",
            " [3.486721 ]\n",
            " [3.4868894]\n",
            " [3.4645324]\n",
            " [3.4575744]\n",
            " [3.4610746]\n",
            " [3.4688027]\n",
            " [3.464194 ]\n",
            " [3.470858 ]\n",
            " [3.4795136]\n",
            " [3.4687486]\n",
            " [3.4283023]\n",
            " [3.4065323]\n",
            " [3.3987846]\n",
            " [3.3785272]\n",
            " [3.3858337]\n",
            " [3.383595 ]\n",
            " [3.3788533]\n",
            " [3.3575635]\n",
            " [3.327676 ]\n",
            " [3.2881799]\n",
            " [3.2917519]\n",
            " [3.2955592]\n",
            " [3.2951121]\n",
            " [3.2992516]\n",
            " [3.3009548]\n",
            " [3.3043785]\n",
            " [3.306189 ]\n",
            " [3.3033218]\n",
            " [3.3042278]\n",
            " [3.3160992]\n",
            " [3.321363 ]\n",
            " [3.3459554]\n",
            " [3.3788047]\n",
            " [3.3840442]\n",
            " [3.3732762]\n",
            " [3.362409 ]\n",
            " [3.3546906]\n",
            " [3.3473086]\n",
            " [3.3431418]\n",
            " [3.3348966]\n",
            " [3.3274512]\n",
            " [3.3065195]\n",
            " [3.3904839]\n",
            " [3.456672 ]\n",
            " [3.510313 ]\n",
            " [3.5482883]\n",
            " [3.572548 ]\n",
            " [3.6061783]\n",
            " [3.6280913]\n",
            " [3.6449432]\n",
            " [3.6706572]\n",
            " [3.70666  ]\n",
            " [3.705577 ]\n",
            " [3.7058232]\n",
            " [3.7086704]\n",
            " [3.7101479]\n",
            " [3.7122302]\n",
            " [3.7141514]\n",
            " [3.7173371]\n",
            " [3.7189555]\n",
            " [3.7201052]\n",
            " [3.7214608]\n",
            " [3.7237043]\n",
            " [3.7199626]\n",
            " [3.718665 ]\n",
            " [3.7141528]\n",
            " [3.7129078]\n",
            " [3.711422 ]\n",
            " [3.7079177]\n",
            " [3.7008903]\n",
            " [3.7021484]\n",
            " [3.6966386]\n",
            " [3.6963944]\n",
            " [3.695806 ]\n",
            " [3.6929336]\n",
            " [3.687276 ]\n",
            " [3.686821 ]\n",
            " [3.6906738]\n",
            " [3.6912177]\n",
            " [3.6896458]\n",
            " [3.6884036]\n",
            " [3.6835508]\n",
            " [3.6791592]\n",
            " [3.6758964]\n",
            " [3.6849666]\n",
            " [3.6936405]\n",
            " [3.6372452]\n",
            " [3.5790768]\n",
            " [3.537717 ]\n",
            " [3.4970603]\n",
            " [3.479646 ]\n",
            " [3.4500713]\n",
            " [3.4304056]\n",
            " [3.4236133]\n",
            " [3.4027522]\n",
            " [3.3856726]\n",
            " [3.389408 ]\n",
            " [3.3853798]\n",
            " [3.3750267]\n",
            " [3.3723207]\n",
            " [3.3712635]\n",
            " [3.3807929]\n",
            " [3.3842106]\n",
            " [3.388823 ]\n",
            " [3.3839612]\n",
            " [3.376545 ]\n",
            " [3.374749 ]\n",
            " [3.3759594]\n",
            " [3.3737895]\n",
            " [3.3744025]\n",
            " [3.388949 ]\n",
            " [3.3999197]\n",
            " [3.4078832]\n",
            " [3.4117708]\n",
            " [3.41265  ]\n",
            " [3.424688 ]\n",
            " [3.4286017]\n",
            " [3.4133425]\n",
            " [3.4134362]\n",
            " [3.4057431]\n",
            " [3.3948493]\n",
            " [3.398448 ]\n",
            " [3.389297 ]\n",
            " [3.3913498]\n",
            " [3.3877444]\n",
            " [3.4129453]\n",
            " [3.4107094]\n",
            " [3.4078045]\n",
            " [3.434366 ]\n",
            " [3.4350038]\n",
            " [3.4346204]\n",
            " [3.4351625]\n",
            " [3.4406211]\n",
            " [3.4340203]\n",
            " [3.4374995]\n",
            " [3.418966 ]\n",
            " [3.4184737]\n",
            " [3.4106464]\n",
            " [3.4168484]\n",
            " [3.4085739]\n",
            " [3.4005208]\n",
            " [3.4027677]\n",
            " [3.3886876]\n",
            " [3.386148 ]\n",
            " [3.3857062]\n",
            " [3.3939998]\n",
            " [3.405488 ]\n",
            " [3.4109046]\n",
            " [3.3952663]\n",
            " [3.3699656]\n",
            " [3.350306 ]\n",
            " [3.3336382]\n",
            " [3.3220625]\n",
            " [3.3082604]\n",
            " [3.309431 ]\n",
            " [3.3089151]\n",
            " [3.318859 ]\n",
            " [3.432902 ]\n",
            " [3.5014265]\n",
            " [3.529236 ]\n",
            " [3.542385 ]\n",
            " [3.5446885]\n",
            " [3.5091062]\n",
            " [3.4344969]\n",
            " [3.375241 ]\n",
            " [3.3397717]\n",
            " [3.3135016]\n",
            " [3.29032  ]\n",
            " [3.275113 ]\n",
            " [3.2791708]\n",
            " [3.2893121]\n",
            " [3.2977035]\n",
            " [3.2995913]\n",
            " [3.3012283]\n",
            " [3.3006191]\n",
            " [3.299969 ]\n",
            " [3.2980654]\n",
            " [3.3017254]\n",
            " [3.2940655]\n",
            " [3.2891397]\n",
            " [3.2861357]\n",
            " [3.285521 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# 假設 'true_values' 是新資料的真實標籤\n",
        "true_values = new_data['time_diff_to_first_exhausted'].iloc[time_steps:].values  # 根據時間步長調整\n",
        "\n",
        "# 計算評估指標\n",
        "mae = mean_absolute_error(true_values, predictions)\n",
        "mse = mean_squared_error(true_values, predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(true_values, predictions)\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "print(f\"R² Score: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfrjbU8RkcLq",
        "outputId": "c05751b3-3fb0-44c4-920d-7d6df9f7c60e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 11.3557\n",
            "Mean Squared Error (MSE): 311.5042\n",
            "Root Mean Squared Error (RMSE): 17.6495\n",
            "R² Score: -0.1498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 將預測結果存到 DataFrame\n",
        "predictions_df = pd.DataFrame(predictions, columns=['Predicted_time_diff'])\n",
        "\n",
        "# 保存預測結果\n",
        "predictions_df.to_csv('predictions.csv', index=False)"
      ],
      "metadata": {
        "id": "WrXfYivekcEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##XGBoost"
      ],
      "metadata": {
        "id": "u0WL5Ztbd6Me"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === 重建回歸模型代碼 ===\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from xgboost import XGBRegressor\n",
        "import joblib\n",
        "\n",
        "# 訓練模型函數\n",
        "def fit_xgb_model(X_train, y_train):\n",
        "    model = XGBRegressor(\n",
        "        objective='reg:squarederror',\n",
        "        max_depth=6,\n",
        "        learning_rate=0.05,\n",
        "        n_estimators=300,\n",
        "        random_state=42\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "\n",
        "# 讀取資料\n",
        "data = pd.read_csv('/content/all_plot_cleandata.csv', encoding='utf-8')\n",
        "\n",
        "# 特徵工程與預處理\n",
        "def calculate_time_diff(df):\n",
        "    start_time = df['time'].iloc[0]\n",
        "    if df['Transition'].sum() > 0:\n",
        "        transition_time = df.loc[df['Transition'] == 1, 'time'].iloc[0]\n",
        "        df['time_diff_to_first_exhausted'] = transition_time - start_time\n",
        "    else:\n",
        "        df['time_diff_to_first_exhausted'] = 0\n",
        "    return df\n",
        "\n",
        "data = data.groupby('USER_ID_HASH', group_keys=False, as_index=False).apply(calculate_time_diff)\n",
        "\n",
        "data['distance_moving_avg'] = data.groupby('USER_ID_HASH')['distance'].transform(\n",
        "    lambda x: x.rolling(window=5, min_periods=1).mean()\n",
        ")\n",
        "\n",
        "data['distance_variance'] = data.groupby('USER_ID_HASH')['distance'].transform(\n",
        "    lambda x: x.rolling(window=5, min_periods=1).var()\n",
        ")\n",
        "\n",
        "# 填補缺失值\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "data['time_diff_to_first_exhausted'] = imputer.fit_transform(data[['time_diff_to_first_exhausted']])\n",
        "\n",
        "# 特徵選擇\n",
        "corr_matrix = data.corr()\n",
        "mean_corr = corr_matrix.mean().sort_values(ascending=False)\n",
        "top_features = mean_corr.head(7).index\n",
        "\n",
        "# 訓練模型與調參\n",
        "features = data[top_features]\n",
        "target = data['time_diff_to_first_exhausted']\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "model = fit_xgb_model(X_train, y_train)\n",
        "joblib.dump(model, 'xgboost_regression_model.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZSwkgrKg0gX",
        "outputId": "20ff13fd-1b31-4ff5-a113-6c716474bf7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-dbf6cb6cf8fb>:36: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  data = data.groupby('USER_ID_HASH', group_keys=False, as_index=False).apply(calculate_time_diff)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['xgboost_regression_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === 測試模型代碼 ===\n",
        "test_data = pd.read_csv('/content/RYAN_final_data.csv', encoding='utf-8')\n",
        "\n",
        "test_data['Transition'] = test_data.groupby('USER_ID_HASH')['Exhausted_state'].transform(\n",
        "    lambda x: (x.shift() == 0) & (x == 1)\n",
        ").astype(int)\n",
        "\n",
        "test_data = test_data.groupby('USER_ID_HASH', group_keys=False, as_index=False).apply(calculate_time_diff)\n",
        "\n",
        "test_data['distance_moving_avg'] = test_data.groupby('USER_ID_HASH')['distance'].transform(\n",
        "    lambda x: x.rolling(window=5, min_periods=1).mean()\n",
        ")\n",
        "\n",
        "test_data['time_diff_to_first_exhausted'] = imputer.transform(test_data[['time_diff_to_first_exhausted']])\n",
        "\n",
        "test_features = test_data[top_features]\n",
        "new_predictions = model.predict(test_features)\n",
        "\n",
        "# 模型評估與視覺化\n",
        "new_report = classification_report(test_data['Transition'], new_predictions, output_dict=True)\n",
        "new_result_df = pd.DataFrame(new_report).transpose()\n",
        "print(new_result_df)\n",
        "\n",
        "cm = confusion_matrix(test_data['Transition'], new_predictions)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Transition', 'Transition'], yticklabels=['No Transition', 'Transition'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('New Test Set Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# 顯示ROC與PR曲線\n",
        "probs = model.predict_proba(test_features)[:, 1]\n",
        "fpr, tpr, _ = roc_curve(test_data['Transition'], probs)\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc_score(test_data['Transition'], probs):.2f})\")\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(test_data['Transition'], probs)\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(recall, precision, label='Precision-Recall Curve')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "qP_nwQQKbfYM",
        "outputId": "a6be8678-5751-4ff5-9423-aab5006c990c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-5d3725cc75e0>:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  test_data = test_data.groupby('USER_ID_HASH', group_keys=False, as_index=False).apply(calculate_time_diff)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'classification_report' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5d3725cc75e0>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# 模型評估與視覺化\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mnew_report\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Transition'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mnew_result_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_report\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_result_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'classification_report' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 匯入必要函式庫\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, mean_absolute_percentage_error\n",
        "from sklearn.impute import KNNImputer\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# === 步驟 1: 讀取資料 ===\n",
        "file_path = '/content/all_plot_cleandata.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# === 步驟 2: 新增轉變標籤 ===\n",
        "data['Transition'] = data.groupby('USER_ID_HASH')['Exhausted_state'].transform(\n",
        "    lambda x: (x.shift() == 0) & (x == 1)\n",
        ").astype(int)\n",
        "\n",
        "# === 步驟 3: 計算首次轉變時間差 ===\n",
        "def calculate_time_diff(df):\n",
        "    start_time = df['time'].iloc[0]\n",
        "    if df['Transition'].sum() > 0:  # 如果有轉變\n",
        "        transition_time = df.loc[df['Transition'] == 1, 'time'].iloc[0]\n",
        "        df['time_diff_to_first_exhausted'] = transition_time - start_time\n",
        "    else:\n",
        "        df['time_diff_to_first_exhausted'] = 0  # 填補為 0\n",
        "    return df\n",
        "\n",
        "data = data.groupby('USER_ID_HASH', group_keys=False, as_index=False).apply(calculate_time_diff)\n",
        "\n",
        "# === 步驟 4: 計算移動特徵 ===\n",
        "def add_moving_features(df):\n",
        "    df['distance_moving_avg'] = df.groupby('USER_ID_HASH')['distance'].transform(\n",
        "        lambda x: x.rolling(window=5, min_periods=1).mean()\n",
        "    )\n",
        "    df['cumulative_distance'] = df.groupby('USER_ID_HASH')['distance'].cumsum()\n",
        "    df['cumulative_time'] = df.groupby('USER_ID_HASH')['time'].transform(lambda x: x - x.min())\n",
        "    return df\n",
        "\n",
        "data = add_moving_features(data)\n",
        "\n",
        "# === 步驟 5: 過濾資料 ===\n",
        "def filter_first_transition(df):\n",
        "    if df['Transition'].sum() == 0:\n",
        "        return df\n",
        "    first_transition_index = df[df['Transition'] == 1].index[0]\n",
        "    return df[df.index <= first_transition_index]\n",
        "\n",
        "filtered_data = data.groupby('USER_ID_HASH', group_keys=False).apply(filter_first_transition).reset_index(drop=True)\n",
        "\n",
        "# 填補缺失值\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "filtered_data.fillna(0, inplace=True)  # 避免 NaN 引發錯誤\n",
        "\n",
        "# === 步驟 6: 特徵選擇 ===\n",
        "correlation_matrix = filtered_data.corr()\n",
        "target_variable = 'time_diff_to_first_exhausted'\n",
        "\n",
        "# 對數變換目標值\n",
        "filtered_data['log_time_diff'] = np.log1p(filtered_data[target_variable])\n",
        "\n",
        "selected_features = correlation_matrix[target_variable][correlation_matrix[target_variable].abs() > 0.2].index.tolist()\n",
        "selected_features.remove(target_variable)\n",
        "\n",
        "# 儲存選擇的特徵\n",
        "selected_features_file = '/content/selected_features.pkl'\n",
        "joblib.dump(selected_features, selected_features_file)\n",
        "print(f\"\\n特徵選擇結果已儲存至: {selected_features_file}\")\n",
        "\n",
        "# 確保完整的特徵名稱一致性\n",
        "X = filtered_data[selected_features]\n",
        "y = filtered_data['log_time_diff']\n",
        "\n",
        "# === 步驟 7: 資料切分 ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# === 步驟 8: 建立與訓練 XGBoost 模型 ===\n",
        "xgb_model = XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1, subsample=0.8, random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# 儲存模型至檔案\n",
        "model_file = '/content/xgb_model.pkl'\n",
        "try:\n",
        "    joblib.dump(xgb_model, model_file)\n",
        "    print(f\"\\n模型已成功儲存至: {model_file}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n模型儲存失敗: {e}\")\n",
        "\n",
        "# === 步驟 9: 模型評估 ===\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "\n",
        "# 還原對數變換\n",
        "y_test_original = np.expm1(y_test)\n",
        "y_pred_original = np.expm1(y_pred)\n",
        "\n",
        "mae = mean_absolute_error(y_test_original, y_pred_original)\n",
        "r2 = r2_score(y_test_original, y_pred_original)\n",
        "mse = mean_squared_error(y_test_original, y_pred_original)\n",
        "mape = mean_absolute_percentage_error(y_test_original, y_pred_original)\n",
        "\n",
        "accuracy = np.mean(np.round(y_pred_original) == np.round(y_test_original))\n",
        "\n",
        "print(f\"模型: XGBoost Regressor\")\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "print(f\"MSE: {mse:.4f}\")\n",
        "print(f\"R² 分數: {r2:.4f}\")\n",
        "print(f\"MAPE: {mape:.4f}\")\n",
        "print(f\"準確率 (Accuracy): {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MhYUadflkM3",
        "outputId": "125ef6d3-3bd2-4379-a04f-7ddf83aea07e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-b9a0801792ef>:29: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  data = data.groupby('USER_ID_HASH', group_keys=False, as_index=False).apply(calculate_time_diff)\n",
            "<ipython-input-1-b9a0801792ef>:49: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  filtered_data = data.groupby('USER_ID_HASH', group_keys=False).apply(filter_first_transition).reset_index(drop=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "特徵選擇結果已儲存至: /content/selected_features.pkl\n",
            "\n",
            "模型已成功儲存至: /content/xgb_model.pkl\n",
            "模型: XGBoost Regressor\n",
            "MAE: 0.0744\n",
            "MSE: 0.5164\n",
            "R² 分數: 0.9952\n",
            "MAPE: 23609217710042.2539\n",
            "準確率 (Accuracy): 0.9862\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##最終程式碼"
      ],
      "metadata": {
        "id": "ZSihS706F805"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 匯入必要函式庫\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, mean_absolute_percentage_error\n",
        "from sklearn.impute import KNNImputer\n",
        "from xgboost import XGBRegressor\n",
        "from tensorflow.keras.models import Sequential, save_model\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# === 步驟 1: 讀取資料 ===\n",
        "file_path = '/content/all_plot_cleandata.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# === 步驟 2: 新增轉變標籤 ===\n",
        "data['Transition'] = data.groupby('USER_ID_HASH')['Exhausted_state'].transform(\n",
        "    lambda x: (x.shift() == 0) & (x == 1)\n",
        ").astype(int)\n",
        "\n",
        "# === 步驟 3: 計算首次轉變時間差 ===\n",
        "def calculate_time_diff(df):\n",
        "    start_time = df['time'].iloc[0]\n",
        "    if df['Transition'].sum() > 0:  # 如果有轉變\n",
        "        transition_time = df.loc[df['Transition'] == 1, 'time'].iloc[0]\n",
        "        df['time_diff_to_first_exhausted'] = transition_time - start_time\n",
        "    else:\n",
        "        df['time_diff_to_first_exhausted'] = 0  # 填補為 0\n",
        "    return df\n",
        "\n",
        "data = data.groupby('USER_ID_HASH', group_keys=False, as_index=False).apply(calculate_time_diff)\n",
        "\n",
        "# === 步驟 4: 計算移動特徵與累積效應特徵 ===\n",
        "def add_moving_features(df):\n",
        "    df['distance_moving_avg'] = df.groupby('USER_ID_HASH')['distance'].transform(\n",
        "        lambda x: x.rolling(window=3, min_periods=1).mean()\n",
        "    )\n",
        "    df['cumulative_distance'] = df.groupby('USER_ID_HASH')['distance'].cumsum()\n",
        "    df['cumulative_time'] = df.groupby('USER_ID_HASH')['time'].transform(lambda x: x - x.min())\n",
        "    return df\n",
        "\n",
        "data = add_moving_features(data)\n",
        "\n",
        "# === 步驟 5: 過濾資料 ===\n",
        "def filter_first_transition(df):\n",
        "    if df['Transition'].sum() == 0:\n",
        "        return df\n",
        "    first_transition_index = df[df['Transition'] == 1].index[0]\n",
        "    return df[df.index <= first_transition_index]\n",
        "\n",
        "filtered_data = data.groupby('USER_ID_HASH', group_keys=False).apply(filter_first_transition).reset_index(drop=True)\n",
        "\n",
        "# 填補缺失值\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "filtered_data.fillna(0, inplace=True)  # 避免 NaN 引發錯誤\n",
        "\n",
        "# === 步驟 6: 特徵選擇 ===\n",
        "correlation_matrix = filtered_data.corr()\n",
        "target_variable = 'time_diff_to_first_exhausted'\n",
        "\n",
        "# 對數變換目標值\n",
        "filtered_data['log_time_diff'] = np.log1p(filtered_data[target_variable] + 1e-5)\n",
        "\n",
        "selected_features = correlation_matrix[target_variable][correlation_matrix[target_variable].abs() > 0.2].index.tolist()\n",
        "selected_features.remove(target_variable)\n",
        "\n",
        "print(selected_features)\n",
        "\n",
        "# 儲存選擇的特徵\n",
        "selected_features_file = '/content/selected_features.pkl'\n",
        "joblib.dump(selected_features, selected_features_file)\n",
        "print(f\"\\n特徵選擇結果已儲存至: {selected_features_file}\")\n",
        "\n",
        "# 確保完整的特徵名稱一致性\n",
        "X = filtered_data[selected_features]\n",
        "y = filtered_data['log_time_diff']\n",
        "\n",
        "# === 步驟 7: 資料切分 ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# === 步驟 8: 建立與訓練 XGBoost 模型 ===\n",
        "xgb_model = XGBRegressor(n_estimators=300, max_depth=5, learning_rate=0.1, subsample=0.8, random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# 儲存模型至檔案\n",
        "model_file = '/content/xgb_model.pkl'\n",
        "try:\n",
        "    joblib.dump(xgb_model, model_file)\n",
        "    print(f\"\\nXGBoost 模型已成功儲存至: {model_file}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nXGBoost 模型儲存失敗: {e}\")\n",
        "\n",
        "# === 步驟 9: 建立與訓練 RNN 模型 ===\n",
        "# 標準化數據\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 儲存標準化器\n",
        "scaler_file = '/content/scaler.pkl'\n",
        "joblib.dump(scaler, scaler_file)\n",
        "print(f\"\\n標準化器已成功儲存至: {scaler_file}\")\n",
        "\n",
        "# RNN 需要 3D 輸入\n",
        "X_train_rnn = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
        "X_test_rnn = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
        "\n",
        "y_train_rnn = y_train.values\n",
        "y_test_rnn = y_test.values\n",
        "\n",
        "# 建立 RNN 模型\n",
        "rnn_model = Sequential([\n",
        "    LSTM(100, activation='relu', return_sequences=True, input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2])),\n",
        "    Dropout(0.2),\n",
        "    LSTM(50, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "rnn_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "rnn_model.fit(X_train_rnn, y_train_rnn, epochs=30, batch_size=32, verbose=1)\n",
        "\n",
        "# 儲存 RNN 模型至檔案\n",
        "rnn_model_file = '/content/rnn_model.h5'\n",
        "try:\n",
        "    rnn_model.save(rnn_model_file)\n",
        "    print(f\"\\nRNN 模型已成功儲存至: {rnn_model_file}\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nRNN 模型儲存失敗: {e}\")\n",
        "\n",
        "# === 步驟 10: 評估 XGBoost 和 RNN 模型 ===\n",
        "# XGBoost 評估\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
        "\n",
        "# RNN 評估\n",
        "y_pred_rnn = rnn_model.predict(X_test_rnn).flatten()\n",
        "mae_rnn = mean_absolute_error(y_test, y_pred_rnn)\n",
        "\n",
        "# 還原對數變換\n",
        "y_test_original = np.expm1(y_test)\n",
        "y_pred_xgb_original = np.expm1(y_pred_xgb)\n",
        "y_pred_rnn_original = np.expm1(y_pred_rnn)\n",
        "\n",
        "# 基於模型性能調整權重\n",
        "weight_xgb = 1 / mae_xgb\n",
        "weight_rnn = 1 / mae_rnn\n",
        "total_weight = weight_xgb + weight_rnn\n",
        "weight_xgb /= total_weight\n",
        "weight_rnn /= total_weight\n",
        "\n",
        "# 加權融合\n",
        "y_pred_ensemble = weight_xgb * y_pred_xgb_original + weight_rnn * y_pred_rnn_original\n",
        "\n",
        "# 評估指標\n",
        "mae = mean_absolute_error(y_test_original, y_pred_ensemble)\n",
        "r2 = r2_score(y_test_original, y_pred_ensemble)\n",
        "mse = mean_squared_error(y_test_original, y_pred_ensemble)\n",
        "mape = mean_absolute_percentage_error(y_test_original, y_pred_ensemble)\n",
        "accuracy = np.mean(np.round(y_pred_ensemble) == np.round(y_test_original))\n",
        "\n",
        "print(f\"模型融合 (XGBoost + RNN) 評估:\\nMAE: {mae:.4f}\\nMSE: {mse:.4f}\\nR² 分數: {r2:.4f}\\nMAPE: {mape:.4f}\\n準確率 (Accuracy): {accuracy:.4f}\")\n",
        "print(f\"權重: XGBoost = {weight_xgb:.2f}, RNN = {weight_rnn:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsdSd6hI41wY",
        "outputId": "c51d19ae-424a-4fc5-e033-1e80419f15c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-8171076538e9>:32: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  data = data.groupby('USER_ID_HASH', group_keys=False, as_index=False).apply(calculate_time_diff)\n",
            "<ipython-input-1-8171076538e9>:52: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  filtered_data = data.groupby('USER_ID_HASH', group_keys=False).apply(filter_first_transition).reset_index(drop=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['right_eye_condition', 'left_eye_degree', 'left_eye_shine_degree', 'eye_situation_value1', 'eye_situation_value2', 'eye_situation_value3', 'eye_situation_value5', 'habit1', 'distance', 'time', 'distance_ratio', 'blink_y', 'question_5', 'question_7', 'question_11', 'use_situation2_3至6小時', 'use_situation_value4_電腦自動調整', 'use_situation_value4_每次使用都會調整', 'habit4_0或1次', 'habit4_2或3次', 'habit7_眼部運動', 'question_2_完成學校作業', 'distance_moving_avg']\n",
            "\n",
            "特徵選擇結果已儲存至: /content/selected_features.pkl\n",
            "\n",
            "XGBoost 模型已成功儲存至: /content/xgb_model.pkl\n",
            "\n",
            "標準化器已成功儲存至: /content/scaler.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 1.4754\n",
            "Epoch 2/30\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.0134\n",
            "Epoch 3/30\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5048\n",
            "Epoch 4/30\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3308\n",
            "Epoch 5/30\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2612\n",
            "Epoch 6/30\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2116\n",
            "Epoch 7/30\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2003\n",
            "Epoch 8/30\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1766\n",
            "Epoch 9/30\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1661\n",
            "Epoch 10/30\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1197\n",
            "Epoch 11/30\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1666\n",
            "Epoch 12/30\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1251\n",
            "Epoch 13/30\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1052\n",
            "Epoch 14/30\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1358\n",
            "Epoch 15/30\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1272\n",
            "Epoch 16/30\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1441\n",
            "Epoch 17/30\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1584\n",
            "Epoch 18/30\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1301\n",
            "Epoch 19/30\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1381\n",
            "Epoch 20/30\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1018\n",
            "Epoch 21/30\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1150\n",
            "Epoch 22/30\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1089\n",
            "Epoch 23/30\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1363\n",
            "Epoch 24/30\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1045\n",
            "Epoch 25/30\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1161\n",
            "Epoch 26/30\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1065\n",
            "Epoch 27/30\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1235\n",
            "Epoch 28/30\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1132\n",
            "Epoch 29/30\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1212\n",
            "Epoch 30/30\n",
            "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "RNN 模型已成功儲存至: /content/rnn_model.h5\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "模型融合 (XGBoost + RNN) 評估:\n",
            "MAE: 0.1098\n",
            "MSE: 0.5180\n",
            "R² 分數: 0.9952\n",
            "MAPE: 268.9680\n",
            "準確率 (Accuracy): 0.9493\n",
            "權重: XGBoost = 0.92, RNN = 0.08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# 修改：保留相關性的正負值\n",
        "top_10_features_corr_signed = correlation_matrix[target_variable][selected_features].sort_values(key=lambda x: x.abs(), ascending=False).head(10)\n",
        "\n",
        "# 繪製長條圖（包含正負值）\n",
        "plt.figure(figsize=(12, 6))\n",
        "bars = plt.bar(top_10_features_corr_signed.index, top_10_features_corr_signed.values, color=['green' if val > 0 else 'red' for val in top_10_features_corr_signed.values])\n",
        "\n",
        "# 添加數值標籤\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width() / 2, height, f\"{height:.2f}\", ha='center', va='bottom' if height > 0 else 'top')\n",
        "\n",
        "plt.title(\"top 10 features most relevant to the target variable\")\n",
        "plt.xlabel(\"feature name\")\n",
        "plt.ylabel(\"correlation value\")\n",
        "plt.axhline(0, color='black', linewidth=0.8, linestyle='--')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KveCZ79cmyjs",
        "outputId": "8665d186-e670-4beb-d626-a7cf4db806e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-438bddd35290>:20: UserWarning: Glyph 38651 (\\N{CJK UNIFIED IDEOGRAPH-96FB}) missing from current font.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-2-438bddd35290>:20: UserWarning: Glyph 33126 (\\N{CJK UNIFIED IDEOGRAPH-8166}) missing from current font.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-2-438bddd35290>:20: UserWarning: Glyph 33258 (\\N{CJK UNIFIED IDEOGRAPH-81EA}) missing from current font.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-2-438bddd35290>:20: UserWarning: Glyph 21205 (\\N{CJK UNIFIED IDEOGRAPH-52D5}) missing from current font.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-2-438bddd35290>:20: UserWarning: Glyph 35519 (\\N{CJK UNIFIED IDEOGRAPH-8ABF}) missing from current font.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-2-438bddd35290>:20: UserWarning: Glyph 25972 (\\N{CJK UNIFIED IDEOGRAPH-6574}) missing from current font.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-2-438bddd35290>:20: UserWarning: Glyph 27599 (\\N{CJK UNIFIED IDEOGRAPH-6BCF}) missing from current font.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-2-438bddd35290>:20: UserWarning: Glyph 27425 (\\N{CJK UNIFIED IDEOGRAPH-6B21}) missing from current font.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-2-438bddd35290>:20: UserWarning: Glyph 20351 (\\N{CJK UNIFIED IDEOGRAPH-4F7F}) missing from current font.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-2-438bddd35290>:20: UserWarning: Glyph 29992 (\\N{CJK UNIFIED IDEOGRAPH-7528}) missing from current font.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-2-438bddd35290>:20: UserWarning: Glyph 37117 (\\N{CJK UNIFIED IDEOGRAPH-90FD}) missing from current font.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-2-438bddd35290>:20: UserWarning: Glyph 26371 (\\N{CJK UNIFIED IDEOGRAPH-6703}) missing from current font.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-2-438bddd35290>:20: UserWarning: Glyph 30524 (\\N{CJK UNIFIED IDEOGRAPH-773C}) missing from current font.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-2-438bddd35290>:20: UserWarning: Glyph 37096 (\\N{CJK UNIFIED IDEOGRAPH-90E8}) missing from current font.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-2-438bddd35290>:20: UserWarning: Glyph 36939 (\\N{CJK UNIFIED IDEOGRAPH-904B}) missing from current font.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-2-438bddd35290>:20: UserWarning: Glyph 33267 (\\N{CJK UNIFIED IDEOGRAPH-81F3}) missing from current font.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-2-438bddd35290>:20: UserWarning: Glyph 23567 (\\N{CJK UNIFIED IDEOGRAPH-5C0F}) missing from current font.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-2-438bddd35290>:20: UserWarning: Glyph 26178 (\\N{CJK UNIFIED IDEOGRAPH-6642}) missing from current font.\n",
            "  plt.tight_layout()\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 38651 (\\N{CJK UNIFIED IDEOGRAPH-96FB}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 33126 (\\N{CJK UNIFIED IDEOGRAPH-8166}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 33258 (\\N{CJK UNIFIED IDEOGRAPH-81EA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 21205 (\\N{CJK UNIFIED IDEOGRAPH-52D5}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 35519 (\\N{CJK UNIFIED IDEOGRAPH-8ABF}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 25972 (\\N{CJK UNIFIED IDEOGRAPH-6574}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 27599 (\\N{CJK UNIFIED IDEOGRAPH-6BCF}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 27425 (\\N{CJK UNIFIED IDEOGRAPH-6B21}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 20351 (\\N{CJK UNIFIED IDEOGRAPH-4F7F}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 29992 (\\N{CJK UNIFIED IDEOGRAPH-7528}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 37117 (\\N{CJK UNIFIED IDEOGRAPH-90FD}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 26371 (\\N{CJK UNIFIED IDEOGRAPH-6703}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 30524 (\\N{CJK UNIFIED IDEOGRAPH-773C}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 37096 (\\N{CJK UNIFIED IDEOGRAPH-90E8}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 36939 (\\N{CJK UNIFIED IDEOGRAPH-904B}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 33267 (\\N{CJK UNIFIED IDEOGRAPH-81F3}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 23567 (\\N{CJK UNIFIED IDEOGRAPH-5C0F}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 26178 (\\N{CJK UNIFIED IDEOGRAPH-6642}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 匯入必要函式庫\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, mean_absolute_percentage_error\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# === 步驟 1: 載入模型與測試資料 ===\n",
        "xgb_model_file = '/content/xgb_model.pkl'\n",
        "selected_features_file = '/content/selected_features.pkl'\n",
        "rnn_model_file = '/content/rnn_model.h5'\n",
        "scaler_file = '/content/scaler.pkl'\n",
        "joy_file_path = '/content/Joy_final_data.csv'\n",
        "\n",
        "# 載入模型\n",
        "xgb_model = joblib.load(xgb_model_file)\n",
        "rnn_model = load_model(rnn_model_file)\n",
        "scaler = joblib.load(scaler_file)\n",
        "print(f\"\\n模型已成功載入: XGBoost: {xgb_model_file}, RNN: {rnn_model_file}, Scaler: {scaler_file}\")\n",
        "\n",
        "# 讀取測試資料\n",
        "joy_data = pd.read_csv(joy_file_path)\n",
        "\n",
        "# === 資料預處理 ===\n",
        "def process_joy_data(df):\n",
        "    df['Transition'] = df.groupby('USER_ID_HASH')['Exhausted_state'].transform(\n",
        "        lambda x: (x.shift() == 0) & (x == 1)\n",
        "    ).astype(int)\n",
        "\n",
        "    def calculate_time_diff(df):\n",
        "        start_time = df['time'].iloc[0]\n",
        "        if df['Transition'].sum() > 0:\n",
        "            transition_time = df.loc[df['Transition'] == 1, 'time'].iloc[0]\n",
        "            df['time_diff_to_first_exhausted'] = transition_time - start_time\n",
        "        else:\n",
        "            df['time_diff_to_first_exhausted'] = 0\n",
        "        return df\n",
        "\n",
        "    df = df.groupby('USER_ID_HASH', group_keys=False, as_index=False).apply(calculate_time_diff)\n",
        "\n",
        "    def add_moving_features(df):\n",
        "        df['distance_moving_avg'] = df.groupby('USER_ID_HASH')['distance'].transform(\n",
        "            lambda x: x.rolling(window=5, min_periods=1).mean()\n",
        "        )\n",
        "        df['cumulative_distance'] = df.groupby('USER_ID_HASH')['distance'].cumsum()\n",
        "        df['cumulative_time'] = df.groupby('USER_ID_HASH')['time'].transform(lambda x: x - x.min())\n",
        "        return df\n",
        "\n",
        "    df = add_moving_features(df)\n",
        "\n",
        "    def filter_first_transition(df):\n",
        "        if df['Transition'].sum() == 0:\n",
        "            return df\n",
        "        first_transition_index = df[df['Transition'] == 1].index[0]\n",
        "        return df[df.index <= first_transition_index]\n",
        "\n",
        "    filtered_data = df.groupby('USER_ID_HASH', group_keys=False).apply(filter_first_transition).reset_index(drop=True)\n",
        "\n",
        "    # 填補缺失值\n",
        "    imputer = KNNImputer(n_neighbors=5)\n",
        "    filtered_data.fillna(0, inplace=True)  # 避免 NaN 引發錯誤\n",
        "\n",
        "    return filtered_data\n",
        "\n",
        "joy_data = process_joy_data(joy_data)\n",
        "\n",
        "# 載入特徵\n",
        "selected_features = joblib.load(selected_features_file)\n",
        "X_joy = joy_data[selected_features]\n",
        "\n",
        "# === 套用標準化器 ===\n",
        "X_joy_scaled = scaler.transform(X_joy)\n",
        "\n",
        "# === XGBoost 預測 ===\n",
        "xgb_predictions = xgb_model.predict(X_joy_scaled)\n",
        "\n",
        "# === RNN 預測 ===\n",
        "# 確保 RNN 的輸入形狀正確\n",
        "X_rnn = X_joy_scaled  # 確保使用標準化後的輸入\n",
        "X_rnn = np.expand_dims(X_rnn, axis=1)  # 加入時間序列維度 (假設 RNN 預期 shape 為 [samples, time_steps, features])\n",
        "rnn_predictions = rnn_model.predict(X_rnn).flatten()\n",
        "\n",
        "# === 加權平均合併預測 ===\n",
        "combined_predictions = 0.07 * xgb_predictions + 0.93 * rnn_predictions\n",
        "\n",
        "# 如果存在實際標籤，計算評估分數\n",
        "if 'time_diff_to_first_exhausted' in joy_data.columns:\n",
        "    joy_mae = mean_absolute_error(joy_data['time_diff_to_first_exhausted'], combined_predictions)\n",
        "    joy_r2 = r2_score(joy_data['time_diff_to_first_exhausted'], combined_predictions)\n",
        "    joy_mse = mean_squared_error(joy_data['time_diff_to_first_exhausted'], combined_predictions)\n",
        "    joy_mape = mean_absolute_percentage_error(joy_data['time_diff_to_first_exhausted'], combined_predictions)\n",
        "    accuracy = np.mean(np.abs(combined_predictions - joy_data['time_diff_to_first_exhausted']) <= 0.5)\n",
        "\n",
        "    print(f\"\\n測試集評估結果:\")\n",
        "    print(f\"MAE: {joy_mae:.4f}\")\n",
        "    print(f\"MSE: {joy_mse:.4f}\")\n",
        "    print(f\"R² 分數: {joy_r2:.4f}\")\n",
        "    print(f\"MAPE: {joy_mape:.4f}\")\n",
        "    print(f\"準確率 (Accuracy): {accuracy:.4f}\")\n",
        "else:\n",
        "    print(\"\\n測試集缺少標籤，無法計算評估分數。\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkaTZZ2vocEO",
        "outputId": "848c3c90-fd5d-4403-bd8b-98bc07c3d87c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "<ipython-input-4-81abb5412590>:41: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df = df.groupby('USER_ID_HASH', group_keys=False, as_index=False).apply(calculate_time_diff)\n",
            "<ipython-input-4-81abb5412590>:59: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  filtered_data = df.groupby('USER_ID_HASH', group_keys=False).apply(filter_first_transition).reset_index(drop=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "模型已成功載入: XGBoost: /content/xgb_model.pkl, RNN: /content/rnn_model.h5, Scaler: /content/scaler.pkl\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step\n",
            "\n",
            "測試集評估結果:\n",
            "MAE: 8.5981\n",
            "MSE: 277.7200\n",
            "R² 分數: -0.1026\n",
            "MAPE: 795777430648453.0000\n",
            "準確率 (Accuracy): 0.7160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === 匯入必要函式庫 ===\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.impute import KNNImputer\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# === 步驟 1: 載入模型與測試資料 ===\n",
        "rnn_model_file = '/content/rnn_model.h5'\n",
        "scaler_file = '/content/scaler.pkl'\n",
        "selected_features_file = '/content/selected_features.pkl'\n",
        "joy_file_path = '/content/Joy_final_data.csv'\n",
        "\n",
        "# 載入 RNN 模型\n",
        "rnn_model = load_model(rnn_model_file)\n",
        "print(f\"\\nRNN 模型已成功載入: {rnn_model_file}\")\n",
        "\n",
        "# 載入標準化器\n",
        "scaler = joblib.load(scaler_file)\n",
        "print(f\"\\n標準化器已成功載入: {scaler_file}\")\n",
        "\n",
        "# 讀取測試資料\n",
        "joy_data = pd.read_csv(joy_file_path)\n",
        "\n",
        "# === 資料預處理 ===\n",
        "def process_joy_data(df):\n",
        "    df['Transition'] = df.groupby('USER_ID_HASH')['Exhausted_state'].transform(\n",
        "        lambda x: (x.shift() == 0) & (x == 1)\n",
        "    ).astype(int)\n",
        "\n",
        "    def calculate_time_diff(df):\n",
        "        start_time = df['time'].iloc[0]\n",
        "        if df['Transition'].sum() > 0:  # 如果有轉變\n",
        "            transition_time = df.loc[df['Transition'] == 1, 'time'].iloc[0]\n",
        "            df['time_diff_to_first_exhausted'] = transition_time - start_time\n",
        "        else:\n",
        "            df['time_diff_to_first_exhausted'] = 0\n",
        "        return df\n",
        "\n",
        "    df = df.groupby('USER_ID_HASH', group_keys=False, as_index=False).apply(calculate_time_diff)\n",
        "\n",
        "    def add_moving_features(df):\n",
        "        df['distance_moving_avg'] = df.groupby('USER_ID_HASH')['distance'].transform(\n",
        "            lambda x: x.rolling(window=5, min_periods=1).mean()\n",
        "        )\n",
        "        return df\n",
        "\n",
        "    df = add_moving_features(df)\n",
        "\n",
        "    def filter_first_transition(df):\n",
        "        if df['Transition'].sum() == 0:\n",
        "            return df\n",
        "        first_transition_index = df[df['Transition'] == 1].index[0]\n",
        "        return df[df.index <= first_transition_index]\n",
        "\n",
        "    filtered_data = df.groupby('USER_ID_HASH', group_keys=False).apply(filter_first_transition).reset_index(drop=True)\n",
        "\n",
        "    # 填補缺失值\n",
        "    imputer = KNNImputer(n_neighbors=5)\n",
        "    filtered_data.fillna(0, inplace=True)  # 避免 NaN 引發錯誤\n",
        "\n",
        "    return filtered_data\n",
        "\n",
        "joy_data = process_joy_data(joy_data)\n",
        "\n",
        "# 載入特徵\n",
        "selected_features = joblib.load(selected_features_file)\n",
        "X_joy = joy_data[selected_features]\n",
        "\n",
        "# === 標準化資料並準備 RNN 輸入 ===\n",
        "X_joy_scaled = scaler.transform(X_joy)\n",
        "X_joy_rnn = X_joy_scaled.reshape((X_joy_scaled.shape[0], 1, X_joy_scaled.shape[1]))\n",
        "\n",
        "# === 預測 ===\n",
        "joy_y_pred = rnn_model.predict(X_joy_rnn).flatten()\n",
        "\n",
        "# 還原對數變換\n",
        "joy_data['Predicted_time_diff'] = np.expm1(joy_y_pred)\n",
        "\n",
        "# 如果存在實際標籤，計算評估分數\n",
        "if 'time_diff_to_first_exhausted' in joy_data.columns:\n",
        "    joy_y_actual = joy_data['time_diff_to_first_exhausted']\n",
        "    joy_mae = mean_absolute_error(joy_y_actual, joy_data['Predicted_time_diff'])\n",
        "    joy_r2 = r2_score(joy_y_actual, joy_data['Predicted_time_diff'])\n",
        "    joy_mse = mean_squared_error(joy_y_actual, joy_data['Predicted_time_diff'])\n",
        "    joy_mape = mean_absolute_percentage_error(joy_y_actual, joy_data['Predicted_time_diff'])\n",
        "\n",
        "    print(f\"\\n測試集評估結果:\")\n",
        "    print(f\"MAE: {joy_mae:.4f}\")\n",
        "    print(f\"MSE: {joy_mse:.4f}\")\n",
        "    print(f\"R² 分數: {joy_r2:.4f}\")\n",
        "    print(f\"MAPE: {joy_mape:.4f}\")\n",
        "else:\n",
        "    print(\"\\n測試集缺少標籤，無法計算評估分數。\")\n",
        "\n",
        "# 儲存預測結果\n",
        "output_file = '/content/Joy_final_predictions_rnn.csv'\n",
        "joy_data.to_csv(output_file, index=False)\n",
        "print(f\"\\n預測結果已儲存至: {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9ILVUfg5xLc",
        "outputId": "29f991e3-11b3-4347-e480-9e6852b34ea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "<ipython-input-16-a020de519786>:41: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df = df.groupby('USER_ID_HASH', group_keys=False, as_index=False).apply(calculate_time_diff)\n",
            "<ipython-input-16-a020de519786>:57: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  filtered_data = df.groupby('USER_ID_HASH', group_keys=False).apply(filter_first_transition).reset_index(drop=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "RNN 模型已成功載入: /content/rnn_model.h5\n",
            "\n",
            "標準化器已成功載入: /content/scaler.pkl\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step\n",
            "\n",
            "測試集評估結果:\n",
            "MAE: 2.4742\n",
            "MSE: 33.3932\n",
            "R² 分數: 0.8674\n",
            "MAPE: 31328510573605.9922\n",
            "\n",
            "預測結果已儲存至: /content/Joy_final_predictions_rnn.csv\n"
          ]
        }
      ]
    }
  ]
}